{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ylase9l7HY-0"
      },
      "source": [
        "# Tutorial 3\n",
        "\n",
        "## 1. Backpropagation (without Python)\n",
        "\n",
        "Take a look at the following simple neural network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kxObIJGHY-7"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://raw.githubusercontent.com/SvenKlaassen/DL-Lecture-Figures/main/figures/simple_nn.png\" alt=\"Simple Network\" style=\"width: 800px;\"/><br>\n",
        "<b>Figure 1:</b> Simple Neural Network.</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OHqvm9kHY-8"
      },
      "source": [
        "Here, $\\sigma_1$ and $\\sigma_2$ are ReLU. Further the weights are set to\n",
        "\n",
        "$$ v_1=\\begin{pmatrix} 1\\\\2 \\end{pmatrix}, v_2=\\begin{pmatrix} -3\\\\4 \\end{pmatrix} \\text{ and }w=\\begin{pmatrix} -2\\\\1\\\\0.5 \\end{pmatrix}.$$\n",
        "\n",
        "Assume you observe the features $x=(1,1)^T$ with outcome $y=4$.\n",
        "\n",
        "* Calculate one forward pass through the model to obtain the predicted value $\\hat{y}$. What is the corresponding squared loss?\n",
        "\n",
        "* Perform a backward pass through the model and calculate the gradient of the loss function with respect to all parameters of the model.\n",
        "\n",
        "* (Optional) Validate your results using python."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "v1 = torch.tensor([1, 2])\n",
        "v2 = torch.tensor([-3, 4])\n",
        "w = torch.tensor([-2.0, 1.0, 0.5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sigma_1: 3\n",
            "sigma_2: 1\n",
            "w^T sigma(x): -4.5\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rDCiIVbHY--"
      },
      "source": [
        "## 2. Neural Network\n",
        "\n",
        "### Dataset\n",
        "\n",
        "Start by importing the necessary modules."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "H6ICpRyCHY-_"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUM_LJDYHY_B"
      },
      "source": [
        "Next, we load the famous [MNIST](http://yann.lecun.com/exdb/mnist/) dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vVwbIrf7HY_C"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:02<00:00, 4.47MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 255kB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 2.19MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 996kB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "mnist_train = datasets.MNIST(root='./data', train=True, download=True,   transform=torchvision.transforms.Compose([\n",
        "                               torchvision.transforms.ToTensor(),\n",
        "                               torchvision.transforms.Normalize(\n",
        "                                 (0.1307,), (0.3081,))\n",
        "                             ]))\n",
        "mnist_test = datasets.MNIST(root='./data', train=False, download=True,   transform=torchvision.transforms.Compose([\n",
        "                               torchvision.transforms.ToTensor(),\n",
        "                               torchvision.transforms.Normalize(\n",
        "                                 (0.1307,), (0.3081,))\n",
        "                             ])) #normalize on the training dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8C1rwK0HY_E"
      },
      "source": [
        "The dataset contains $70,000$ observations of handwritten digits with corresponding labels. Here, the data is transformed to a tensor and normalized ($0.1307$ and $0.3081$ are the mean and the standard deviation on the training set)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "4OIxVzQDHY_F"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(60000, 10000)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(mnist_train), len(mnist_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_container = [i for i in range (1000)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "[32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "[64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "[96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "[128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "[32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "[64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "[96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "[128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "[32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "[64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "[96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "[128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "[32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "[64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "[96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "[128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "[32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "[64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "[96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "[128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159]\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "batch_size = 32 \n",
        "\n",
        "i = 0\n",
        "epochs = 5\n",
        "\n",
        "for epoch in range (epochs):\n",
        "    i = 0\n",
        "    while i < 5:\n",
        "        batched_data = data_container[i*batch_size:(i+1)*batch_size]\n",
        "        print(\"\\n\")\n",
        "        print(batched_data)\n",
        "        print(\"\\n\")\n",
        "        i += 1\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBvhVp-wHY_G"
      },
      "source": [
        "* Construct a `DataLoader` for the training set by using `torch.utils.data.DataLoader` directly (batch sizes of $64$ and $128$) and set a seed for the random number generator. Additionally, create an `DataLoader` for the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "LYGAX3TDHY_H"
      },
      "outputs": [],
      "source": [
        "train_loader = torch.utils.data.DataLoader(mnist_train,10,shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2\n",
            "2\n",
            "2\n"
          ]
        }
      ],
      "source": [
        "i = 0\n",
        "for batch in iter (train_loader): \n",
        "    while i < 3:\n",
        "        print(len(batch))\n",
        "        i +=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[tensor([[[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
              "           [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
              "           [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
              "           ...,\n",
              "           [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
              "           [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
              "           [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
              " \n",
              " \n",
              "         [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
              "           [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
              "           [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
              "           ...,\n",
              "           [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
              "           [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
              "           [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
              " \n",
              " \n",
              "         [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
              "           [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
              "           [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
              "           ...,\n",
              "           [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
              "           [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
              "           [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
              " \n",
              " \n",
              "         ...,\n",
              " \n",
              " \n",
              "         [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
              "           [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
              "           [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
              "           ...,\n",
              "           [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
              "           [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
              "           [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
              " \n",
              " \n",
              "         [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
              "           [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
              "           [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
              "           ...,\n",
              "           [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
              "           [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
              "           [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
              " \n",
              " \n",
              "         [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
              "           [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
              "           [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
              "           ...,\n",
              "           [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
              "           [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
              "           [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]]]),\n",
              " tensor([6, 9, 6, 4, 0, 8, 2, 8, 8, 7])]"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "next(iter(train_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "example = (train_loader) #iter zum interierbare Objekt machen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFuVMMgPHY_H"
      },
      "source": [
        "* Take a look at the data examples by iterating the `DataLoader` once over the training set. Save the batch (e.g. as `example`)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzhlOVlAHY_I"
      },
      "source": [
        "**Digression:** Another helpful built-in function of Python is `enumerate`. Try looping over the following list using `enumerate`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6e42vC0EHY_J"
      },
      "outputs": [],
      "source": [
        "list = ['Item 1', 'Item 2', 'Item 3']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "dt0sQinvHY_J"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 Item 1\n",
            "1 Item 2\n",
            "2 Item 3\n"
          ]
        }
      ],
      "source": [
        "for counter, item in enumerate(list):\n",
        "    print(counter, item)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5HLRsbDHY_K"
      },
      "source": [
        "For our purposes, `enumerate` can be used on the `DataLoader`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "X0tjEiP0HY_K"
      },
      "outputs": [],
      "source": [
        "examples = enumerate(train_loader)\n",
        "batch_idx, (example_features, example_labels) = next(examples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5-xP4dMHY_K"
      },
      "source": [
        "The following code chunk displays the features as an imange and the corresponding labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "Gdg2nEKCHY_L"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/7p/hbft17ts46dckcqpv35r3z6m0000gn/T/ipykernel_6312/595597796.py:6: UserWarning: The figure layout has changed to tight\n",
            "  plt.tight_layout()\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 4 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig = plt.figure()\n",
        "for i in range(4):\n",
        "    plt.subplot(1,4,i+1)\n",
        "    plt.tight_layout()\n",
        "    plt.imshow(example_features[i][0], cmap='gray', interpolation='none')\n",
        "    plt.title(\"Label: {}\".format(example_labels[i]))\n",
        "    plt.xticks([0,14,28])\n",
        "    plt.yticks([0,14,28])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHnl6x9IHY_M"
      },
      "source": [
        "## Implementing a Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TnWZzLyHY_M"
      },
      "source": [
        "Import the `torch.nn` and construct a sequential neural network (choose your own structure; maybe not too large) for classification. Starting with the `nn.Flatten` layer migth be very helpful."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJ4jNeNgHY_N"
      },
      "source": [
        "* Use the `CrossEntropyLoss` (`reduction='sum'` might be helpful later) and `torch.optim.Adam`for optimization.\n",
        "* Initialize all weights of your network from a normal distribution with standard deviation $0.01$.\n",
        "* Before we start training our network, use our `train_loader` and `test_loader` to evaluate the loss on our training and testing data (this might take a while).\n",
        "* Specify the number of epochs to $1$ and start training your network. Afterwards evaluate the loss.\n",
        "* We would like to get more information printed during the training process. Increase the number of epochs to $5$ and every $50$ batches print the current epoch and loss on the batch (you can add the number of used observations in the epoch as well). Further add the end of each epoch evaluate the loss on the training set. Before starting reinitialize the weights randomly.\n",
        "* Next, take a look at a specific predicition on your example batch from above and compare the predictions to the corresponding labels.\n",
        "* Use this to evaluate the share of accuracy (share correctly predicted labels) on the test set at each epoch. Additionally, log all the printed losses. Again, before starting reinitialize the weights randomly.\n",
        "* Plot the logged losses in a suitable plot."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5pNvS56HY_N"
      },
      "source": [
        "Neural network modules as well as optimizers have the ability to save and load their internal state using `.state_dict()`.\n",
        "`load_state_dict(state_dict)`. See [here](https://pytorch.org/tutorials/beginner/saving_loading_models.html) for saving and loading models. What does the dictionary save?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywxRUltiHY_O"
      },
      "source": [
        "### GPUs\n",
        "Now, use GPUs for training your model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "nBc72qBbHY_O"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
