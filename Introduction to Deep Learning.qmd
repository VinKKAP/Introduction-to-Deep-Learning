---
title: "Introduction to Deepl-Learning"
format: html
---

The worlds most valuable recource is no longer oul, but data.
*But*: (Big) Data has no value, per se.  The crucial question is what can be learned from the data and what conclusions can be drawn.
-> Two main tasks are prediction and causal inference 

Object Detection Repository: https://github.com/matterport/Mask_RCNN
Wäre funny mal mit rum zu spielen.

Deeplearning ist ein bereich von Machine Learning und dieser wiederum ein Bereich von Artificial Intelligence (AI).

Klassisches Programmieren nutzt Regeln und Daten um eine Funktion (Antwort) zu erstellen, die ein Problem löst.

Machine Learning nutzt Daten und Antworten um eine Funktion zu erstellen, die ein Problem löst.

Wann sollte man Deeplearning nutzen und warum ist es so populär?
    Traditionelle Machine Learning Modelle haben eine begrenzte Performance, um Daten zu verarbeiten. Dies führt zu einem Plateau in der Performance. Deeplearning Modelle haben eine höhere Performance die mit der Menge an daten zunimmt.
    Generell ist zu sagen das die meisten Deeplearning Modelle andere Machine Learning Modelle übertreffen, wenn genug Daten vorhanden sind.

Expressions in Deeplearning
    - Training/Learning/Estimating
    - Weights/Parameters
    - Outcome/Label/ Dependent Variable
    - Features/Independent Variables/ Input/ Regressor

Software-frameworks
    Es gibt verschiedene Frameworks, in dieser Vorlesung wird PyTorch verwendet. Es gibt aber auch Tensorflow, Keras, Theano, Caffe, CNTK, MXNet, Chainer, Deeplearning4j, Gluon, Caffe2, PaddlePaddle, BigDL, DL4J, Neon, CaffeOnSpark. 

Tensors und Linear Algebra
    Deeplearning ist auf Große Datensätze angewiesen und diese können in Form von Tensoren dargestellt werden. Tensoren sind eine Verallgemeinerung von Matrizen und Vektoren. Deshalb ist die Verwendung von Basic Linear Algebra hilfreich und nutzlich.
    In Pytorch gibt es die Klasse Tensor, die die Basis für alle Berechnungen in Pytorch ist. Ein Tensor is eine n-dimensional array von nummerischen Werten. Die Tensor-Klasse ist vergleich mit der Numpy-Array-Klasse, aber mit zusätzlichen Funktionen für GPU-Berechnungen und automatisches Differenzieren.

Create Tensors
    Um einen Tensor zu erstellen, startet man mit dem importieren von torchmodul und erstellt einen simplen tensor.

```{python}
import torch
x = torch.arange(42)
print(x)
```

Als nächstes die eigenschaften des Tensos ausgeben.

```{python} 
print(x.shape)
```

Wenn man die Form neu definieren möchte, kann Numpy hilfreich sein.

```{python} 
X = x.reshape(6,7) #6 Zeilen und 7 Spalten
print(X)
print(X.shape)
```

Die Form eines Tensors kann auch mit -1 definiert werden, um die Form automatisch zu berechnen.

```{python}
X = x.reshape(6,-1) #6 Zeilen und 7 Spalten
print(X)
print(X.shape)
```

```{python}
X = x.reshape(-1,7) #6 Zeilen und 7 Spalten
print(X)
print(X.shape)
```

Anstatt reshape kann auch ein Vektor in einem bestimmten Format erstellt werden.

```{python}
print (torch.tensor([[1,2],[3,4],[5,6]]))
```

Allgemein werden hier die tensoren mit randomisierten Werten, einsen oder nullen bei spezifischen Dimensionen erstellt.

```{python}
zeros = torch.zeros((2,3,4)) # 2 Matrizen mit 3 Zeilen und 4 Spalten
print(zeros)
```

```{python}
ones = torch.ones((2,3,4)) # 2 Matrizen mit 3 Zeilen und 4 Spalten
print(ones)
```

```{python}
random_tensor = torch.randn(2,3,4) # 2 Matrizen mit 3 Zeilen und 4 Spalten
print(random_tensor)
````

Hier erstellt torch.randn einen Tensor mit zufälligen Werten, die einer Normalverteilung folgen.

Tensor Operations
    Tensoren können mit den üblichen Operationen wie Addition, Subtraktion, Multiplikation und Division bearbeitet werden. Diese Operationen können auch auf Tensoren mit unterschiedlichen Formen angewendet werden, wenn die Bedingungen für die Broadcasting-Regeln erfüllt sind. Broadcasting-Regeln sind Regeln, die die Bedingungen für die Anwendung von Operationen auf Tensoren mit unterschiedlichen Formen definieren. Zum Beispiel können zwei Tensoren mit unterschiedlichen Formen addiert werden, wenn die Formen der Tensoren einer oder beiden Dimensionen gleich sind.

```{python}
x = torch.tensor([3.0,2])
y = torch.tensor([4.0,1])
print(x+y, x-y, x*y, x/y, x**2)
```

Außerdem können bekannte funktionen wie exponential oder lograithm angewendet werden.

```{python}
a = torch.exp(x)
print(a, torch.log(a))
```

Außerdem können Tensoren in sehr wichtigen Operationen, welche in concatenate operation (torch.cat) und dot product (torch.mm) bestehen, verwendet werden.

```{python}
cat_0 = torch.cat((zeros,ones), dim=0) # dim=0 bedeutet, dass die Tensoren in der ersten Dimension (Zeilen) zusammengefügt werden
print(cat_0)
```

```{python}
cat_1 = torch.cat((zeros, ones), dim=1) # dim=1 bedeutet, dass die Tensoren in der zweiten Dimension (Spalten) zusammengefügt werden
print(cat_1)
```

```{python}
print(torch.cat((zeros, ones), dim=2)) # dim=2 bedeutet, dass die Tensoren in der dritten Dimension zusammengefügt werden
```

Andere wichtige Operationen sind die Transposition und der Dot-Product zweier Tensoren. Transposition bedeuetet, dass die Zeilen und Spalten eines Tensors vertauscht werden. Der Dot-Product zweier Tensoren ist das Produkt der Elemente der beiden Tensoren. Das Produkt wird berechnet, indem die Elemente der ersten Zeile der ersten Matrix mit den Elementen der ersten Spalte der zweiten Matrix multipliziert werden. Die Ergebnisse werden dann addiert, um das erste Element der Ergebnismatrix zu erhalten.
Der Dot-Product zweier Tensoren kann mit der Funktion torch.mm berechnet werden. 


# Einführung in Machine Learning

```{python}
print(x,y,x < y) 
```
```{python}
print(x.sum(),x.mean())
```

Das Konzept of Broadcasting ist nützlich um kalkulationen zu vereinbaren. Boradcasting beschreibt die Regeln, die die Bedingungen für die Anwendung von Operationen auf Tensoren mit unterschiedlichen Formen definieren. Zum Beispiel können zwei Tensoren mit unterschiedlichen Formen addiert werden, wenn die Formen der Tensoren einer oder beiden Dimensionen gleich sind.

```{python}
x = torch.tensor([[3.0], [2]])
y = torch.tensor([[4.0,1,2]])
print(x.shape, y.shape)
````

Torch.tensor bewirkt, dass die Tensoren die gleiche Form haben. Die Tensoren können dann addiert werden.

```{python}
z = x+y
print(z, z.shape)
```

Der Output zeigt das der Tensor x (dimension 2x1) und y (1x3) werden broadcasted zu zwei einem Tensor z (2x3). Hierbei werden die Tensoren dem Shape des anderen Tensors angepasst. In dem der x Tensor in der zweiten Dimension (Spalten) verdoppelt wird und der y Tensor in der ersten Dimension (Zeilen) verdoppelt wird.

$x+y = \begin{bmatrix} 3 & 3 & 3 \\ 2 & 2 & 2 \end{bmatrix} + \begin{bmatrix} 4 & 1 & 2 \\ 4 & 1 & 2 \end{bmatrix} = \begin{bmatrix} 7 & 4 & 5 \\ 6 & 3 & 4 \end{bmatrix} $

Außerdem können spezifische Elemente mittels indexing und sclicing ausgewählt werden.

```{python}
a = torch.arange(12).reshape(-1,4)
print(a)
```

```{python}
print(a[0,0], a[0,:], a[0:2,0])
```

```{python}
print(a[:,3], a[:,-1])
```

Wie viele andere Numpy Funktionen ist das konvertieren von array zu tensoren sehr hilfreich.

```{python}
b = a.numpy()
print(b)
```

```{python}
print(torch.tensor(b))
```

## Linear Algebra

Da viele Tensoren Matrixen oder Vektoren sein werden, ist es hilfreich anwendungen der Linearen Algebra zu kennen. Ein Vektor ist eine Matrix mit einer Spalte und eine Matrix ist ein Tensor mit zwei Dimensionen. Ein Tensor mit drei Dimensionen ist ein Würfel.

Um das Skalarprodukt (dot product) zu berechnen gilt die Formel:

$x=\begin{bmatrix} x_1 \\ x_2 \\ ... \\ x_p \end{bmatrix}$ und $y=\begin{bmatrix} y_1 \\ y_2 \\ ... \\ y_p \end{bmatrix}$

dann ist
$(x,y) =x^t y = \sum_{i=1}^{p} x_i y_i$

was in torch.dot berechnet werden kann.

```{python}
x = torch.arange(3, dtype = torch.float32)
y = torch.arange(3, dtype = torch.float32)
print(x, y, torch.dot(x,y))
```

Um 
# Diggah wie geht die Formel?

```{python}
A = torch.tensor([[3,1.3,0],[2,5,0.5]])
print(A.shape, x.shape)
```

```{python}
print(torch.mv(A,x))
````

```{python}
B = torch.ones((3,2))
print(torch.mm(A,B))
```

Vektor-Norm bedeutet das die Länge eines Vektors berechnet wird. Die Länge eines Vektors ist die Wurzel der Summe der Quadrate der Elemente des Vektors. Die Norm eines Vektors x ist definiert als ||x|| = sqrt(x^t x). Die Norm eines Vektors kann mit der Funktion torch.norm berechnet werden.

```{python}
print(x,torch.norm(x))
```

Die Euclidean Norm ist ein besonderer Fall der L_p-norm

hier ist der L_1-norm ein wichtiger Fall. Wie unterscheidet sich das verhalten von L_1 und L_2 Normen?
Eine Matrix-norm hat die selben Eigenschaften wie eine Vektor-norm, aber ist definiert ür Matrizen (generell werden normen definiert als Vektor räume). 

Die Frobenius norm ist eine Matrix-norm, die die Länge einer Matrix berechnet. Die Frobenius norm einer Matrix A ist definiert als ||A||_F = sqrt(sum_i sum_j a_ij^2). 

```{python}
print(A, torch.norm(A))
```

Die Frobenius Norm ist ein spezialfall der L_P,q-norm.

## Basics of Machine Learning 

Machine Learning kann als eine Funktionsapproximation gesehen werden. Mit X als den Input und Y als den Output, wird eine Funktion f(X) gesucht, die Y approximiert. Die Funktion f(X) wird durch die Anpassung der Parameter der Funktion an die Daten gelernt. Die Daten werden in Trainings- und Testdaten unterteilt. Die Trainingsdaten werden verwendet, um die Funktion zu lernen und die Testdaten werden verwendet, um die Leistung der Funktion zu bewerten.

Wie X,Y und f_0 aussieht hängt stark davon ab welches learning problem vorliegt. Es gibt zwei Hauptkategorien von learning problems: Supervised und Unsupervised Learning.

Supervised Learning
    In supervised learning wird ein Modell erstellt, das eine Funktion f(X) lernt, die die Beziehung zwischen den Input X und den Output Y approximiert (eine annäherung an den tatsächlichen Wert). Die Trainingsdaten bestehen aus Input-Output-Paaren (X,Y). Das Ziel ist es, eine Funktion zu finden, die die Trainingsdaten gut approximiert und die Testdaten gut generalisiert. Es gibt zwei Hauptkategorien von supervised learning: Regression und Classification.
    Zum Beispiel
    - Image Classification: Ein Bild wird als Input gegeben und das Modell muss das Bild in eine von mehreren Klassen klassifizieren.
    - Sales Prediction: Historische Verkaufsdaten werden als Input gegeben und das Modell muss die zukünftigen Verkaufszahlen vorhersagen.
    - Translation: Ein Satz in einer Sprache wird als Input gegeben und das Modell muss den Satz in eine andere Sprache übersetzen.

Unsupervised Learning
    Im Kontrast zu supervised learning gibt es keine Output-Labels in unsupervised learning. Das Ziel ist es, Muster in den Daten zu finden. Es gibt zwei Hauptkategorien von unsupervised learning: 
    - Clustering und 
    - Dimensionality Reduction.

Semi-Supervised Learning
    Semi-supervised learning ist eine Kombination aus supervised und unsupervised learning. Es wird verwendet, wenn nur ein Teil der Daten gelabelt ist. Das Modell lernt aus den gelabelten und ungelaubelten Daten.

Regression vs. Classification
    Wenn die Target-Variable kontinuierlich ist, wird das Problem als Regression bezeichnet. Wenn die Target-Variable kategorisch ist, wird das Problem als Classification bezeichnet.

## Loss Function
    Die Loss Function ist eine Funktion, die die Differenz zwischen den tatsächlichen und den vorhergesagten Werten misst. Das Ziel ist es, die Loss Function zu minimieren. Die Loss Function hängt von der Art des Problems ab. Zum Beispiel ist die Mean Squared Error (MSE) eine gängige Loss Function für Regression und die Cross-Entropy Loss Function eine gängige Loss Function für Classification.

Mapping: Die Funktion f(x) oder das Model (f) nimmt die Input-Daten (x) und gibt die Output-Daten (y) zurück. Das Ziel ist es, die Funktion f(x) zu lernen, die die Beziehung zwischen den Input- und Output-Daten approximiert.
    Die Loss Funktion misst die Differenz zwischen den tatsächlichen und den vorhergesagten Werten. Das Ziel ist es, die Loss Funktion zu minimieren.
        Durch Optimierungsprozess wie z.B. Gradient Descent wird die Loss Funktion minimiert.
Im Regressions kontext ist ein bekanntes Setting vom Loss der Squared loss. (y_1-y_2)^2. 

Es ist möglich das l_2 norm zu minimieren, um die Loss Function zu minimieren. 

Außerdem gibt es die absolute loss function, die die absolute Differenz zwischen den tatsächlichen und den vorhergesagten Werten misst.

## Risk Minimization
    Das Ziel des Machine Learning ist es, die Loss Function zu minimieren. Das Risiko ist die erwartete Loss Function über alle möglichen Input-Output-Paare. Das Ziel ist es, das Risiko zu minimieren. Das Risiko kann in zwei Teile unterteilt werden: den empirischen Risiko und den strukturellen Risiko. Das empirische Risiko ist der durchschnittliche Loss über die Trainingsdaten. Das strukturelle Risiko ist ein Maß für die Komplexität des Modells. Das Ziel ist es, das strukturelle Risiko zu minimieren, ohne das empirische Risiko zu erhöhen.
    Die Herausforderung ist es den Parameter vecto Ro0 zu finden, welche das risiko minimiert.

    Anstelle alles per Hand zu machen ist es möglich die automatische differenzierung von pytorch zu nutzen.

```{python}
import torch
x_0 = torch.tensor([-.9,.8],requires_grad = True)
print(x_0)
````

requires_grad = True spezifiziert einen Ort im Speicher, wo die Gradienten gespeichert werden.
Das würde eine menge Speicher verbrauchen, wenn für jede neue Variante jeder Wert geupdated wird.

```{python}
fx = sum(x_0**2)
print(fx)
```

We can automatically calculate the gradient of the function with respect to the input using the backpropagatoion.

```{python}
fx.backward()
print(x_0.grad)
```

Here, the backpropagation traces the computatinonal graph backwards to x_0 (in this case only one step) and calculates
the partial derivatives. To detach the calculatios from the computational graph we can use.

```{python}
print(x_0.detach())
```

## Training a Machine Learning Model

In the previous sections, we have defined learning/training a machine learning model as learning parameters/weights, which minimize the empirical risk
In deep learning this is generally done with gradient descent methods due to the cimplicated form of f(x,ro).
1. Erst wrden die Prediction Rule berechnet
2. Dann wird die Loss Function berechnet
3. Dann wird der Gradient der Loss Function berechnet
-----------------------------------------------------
4. Dann wird der Gradient verwendet um die Parameter zu updaten

## Basic Linear Regression

In a basic multicariate linear regression model, we assume that the output Y is a linear function of the inputs X = 1,X1,...,Xp. The model can be written as Y = W0 + W1X1 + ... + WpXp + E, where W0,W1,...,Wp are the parameters of the model and E is the error term. The goal is to learn the parameters W0,W1,...,Wp that minimize the loss function.
Therefore, we can interpret this as minimzing the average squared loss, with the weights w being the parameter vector ro0 we would like to learn.

For linear models there exists an analytical solution (under some mild assumptions). Instead of directly using the analytical solution to estimate the weights w, we apply the gradient descent method.

In the following, we implement basic linear regression including a small bivariate simulation example. We generate n= 200 observationswith the following process.
Y = 2-3X1 - 1.5X2 + E, where E is a random error term.

```{python}
import random; import torch

def dgp_linear_regression(weights, intercept, n):
    X = torch.normal(0, 1, (n, len(weights)))
    Y = intercept + torch.mv(X, weights) + torch.normal(0, 1, (1, n))
    return X, Y.reshape(-1, 1)

true_weights = torch.tensor([-3.0, -1.5])
true_intercept = 2

# Generate data
n_obs = 200
torch.manual_seed(42)  # Set a seed for replicability
features, labels = dgp_linear_regression(true_weights, true_intercept, n_obs)

print(features)
print(labels)
```

Remark that we defined the intercept (or bias) separately (which is more convenient and saves computationla resources).
Let us take a look at the generated data.

```{python}
%matplotlib inline
import numpy as np; import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D; from mpl_toolkits.mplot3d import proj3d

fig = plt.figure(figsize=(20,10), dpi = 100); ax = fig.add_subplot(111,projection='3d')
x1 = features[:,0]
x2 = features[:,1]
y = labels
ax.scatter(x1, x2, y, c='r', marker='o')
ax.set_xlabel('Featue $X_1$'); ax.set_ylabel('Feature $X_2'); ax.set_zlabel('Outcome Y')
plt.show()
```

We will initialize our weights randomly with distribution N(0,0.1) and set the bias to 0.

```{python}
weights = torch.normal(0, 0.1,size = (2, 1), requires_grad = True)
intercept = torch.zeros(1,requires_grad=True)
print(weights)
print(intercept)
```

At first let us calculate the predicted values (with random weights).

```{python}
Y_hat = intercept + torch.mm(features, weights)
print(Y_hat[0:5])
```

Next, we want to calculate the empirical loss.

```{python}
training_loss = torch.mean((Y_hat-labels.reshape(Y_hat.shape))**2)
print(training_loss)
```

here, training_loss.backwards() will compute the graient of loss with repsect to all Tensor that have requires_grad = True. The gradient takes the folowing form:

```{python}
training_loss.backward()
print(weights.grad)
print(intercept.grad)
```

Next, we update the parameters

```{python}
learning_rate = 0.001
with torch.no_grad():
    weights -= learning_rate * weights.grad
    intercept -= learning_rate * intercept.grad

    # Manually zero the gradients after updating weights
    weights.grad.zero_()
    intercept.grad.zero_()

print(weights)
print(intercept)
```

Remark that we used torch.no_grad(), because the parameters have requieres_grad= True, but we dont want to track this step in autograd. Audditionally, we have to reset the gradient to zero, if we want to repeat this step multiple times. 

An alternative way is to operate on weights.data and weights.grad.data Here, tensor.data gives a tensor that shares the storage with tensor, but doenst track history.

```{python}
weights.data -= learning_rate * weights.grad.data
intercept.data -= learning_rate * intercept.grad.data
# Manually zero the gradients after updating weights
weights.grad.data.zero_()
intercept.grad.data.zero_()
print(weights)
print(intercept)
```

We will now combine all of this in a loop (with a slightly larger learning rate) to iteratively minimize the empirical risk (loss function).

```{python}
learning_rate = 0.03
for i in range (500):
    Y_hat = intercept + torch.mm(features, weights)
    training_loss = torch.mean((Y_hat-labels.reshape(Y_hat.shape))**2)
    training_loss.backward()
    with torch.no_grad():
        weights -= learning_rate * weights.grad
        intercept -= learning_rate * intercept.grad
        # Manually zero the gradients after updating weights
        weights.grad.zero_()
        intercept.grad.zero_()

print(weights)
print(intercept)
```

Our parameters are quite close to the true values. Lets take a look at our final model.

```{python}
from matplotlib import cm
xs = np.tile(np.arange(61), (61,1))
ys = np.tile(np.arange(61), (61,1)).T
base_grid = np.arange(-3,3,0.1)
xs = np.tile(base_grid, (len(base_grid),1))
ys = np.tile(base_grid, (len(base_grid),1)).T

zs = xs*weights[0].detach().numpy() + ys*weights[1].detach().numpy() + intercept.detach().numpy()

ax.plot_surface(xs,ys,zs, cmap = cm.coolwarm, alpha = 0.5)
fig
```

## Stochastic Gradient Descent

The training loop from the previous chapter, displays the basic idea of training a machine learning model with descent.
In practice, if the number of observations n is realy large and the function f(x,ro) is more complex we will run into computational problems really fast. In general, the calculation of the gradient on all samples is too costly.
An easy solution is to use a stochastic version of the gradient descent method called stochastic gradient descent.

Instead of using all samples in each interation of the training loop, we will only use a small random subset of the observations, where the subset is called batch. 
Stochastic gradient descent generally refers to only using a single observation for each update step (batch size of one). Very small subsets are usually calld mini-batch, where using the whole sample is called full batch.

The basic idea is that on a random sample the gradient is still a unbiased (but noisy) estimate of the true gradient.

In practice deep learning is done in a series of epochs, where one epoch consists of one backpropagation pass over the whole dataset. 
In the previous example, we did use full batch and each iteration corresponded to one epoch.

General Training Procedure:
    1. Set the number of epochs and the batch size
    2. Randomly devide the training set into batches of the specified batch size. 
    3. Interate the training loop over all batches (each iteration a batch is randomly drawn without replacement).
    4. Repeat steps 2 and 3 for each epoch. 

We will repeat the linear regression example with stochastic gradient descent. At first, we will need a data loader, wich automatically provides the batches.

```{python}
def data_iter(batch_size, features, labels):
    n = len(labels)
    indices = list(range(n))
    random.shuffle(indices)
    for i in range (0,n,batch_size):
        batch_indices = torch.tensor(indices[i:min(i+batch_size,n)])
        yield features[batch_indices], labels[batch_indices]

for X,Y in data_iter(5, features, labels): #test the batches
    print(X, "\n", Y)
    break
```

Now we can repeat the model training.

```{python}
weights = torch.normal(0, 0.1, size=(2, 1), requires_grad=True)
intercept = torch.zeros(1, requires_grad=True)
learning_rate = 0.03
batch_size = 10
n_epochs = 5
for epoch in range (n_epochs):
    for X, Y in data_iter(batch_size, features, labels):
        Y_hat = intercept + torch.mm(X,weights)
        training_loss = torch.mean((Y_hat - Y.reshape(Y_hat.shape))**2)
        training_loss.backward()
        with torch.no_grad():
            weights -= learning_rate * weights.grad
            intercept -= learning_rate * intercept
            weights.grad.zero_()
            intercept.grad.zero_()

print(weights)
print(intercept)
```

There exist a lot of different variants of the stochastic gradient descent algorithms, wich are explaned in more detail in later sections.

## Building Linear Regression using High-Level APIs

How to implement the linear regressino model by using high-level API´s of deep learning frameworks. The first step is to implement a data. Features and labels pass as arguments and specify batch_size when instantiating a data iterator object. Besides boolean value (Values are True or False) is_train indicates wether or not we want the data iterator object to shuffle the data on each epoch (pass through the dataset).

```{python}
from torch.utils import data
def load_array(data_arrays, batch_size, is_train=True):
    """ Construct a PyTorch data iterator. """
    dataset = data.TensorDataset(*data_arrays)
    return data.DataLoader(dataset, batch_size, shuffle=is_train)

batch_size = 10
data_iter = load_array((features, labels), batch_size)
```

Um zu prüfen ob das funktioniert, können wir die ersten Batches ausgeben.

```{python}
print(next(iter(data_iter)))
```

```{python}
from torch import nn
lin_reg = nn.Sequential(nn.Linear(2,1))
```

nn is an neural network in a linear transformation layer. The input and output dimensions are 2 and 1, respectively.
To initalize the weights (with w_0=bias).

```{python}
lin_reg[0].weight.data.normal_(0, 0.1)
lin_reg[0].bias.data.fill_(0)
print(lin_reg[0].weight.data)
print(lin_reg[0].bias.data)
```

Specify the loss:

```{python}
loss = nn.MSELoss()
```

To optimization use torch.optim which is a package implementing various optimization algorithms. 

```{python}
trainer = torch.optim.SGD(lin_reg.parameters(), lr = 0.01)
```

torch.optim.SGD constructs a stochastic gradient descent optimizer for all weights of lin_reg with the lr beeing the learning rate.

```{python}
num_epochs = 5
for epoch in range (num_epochs):
    for X, y in data_iter:
        training_loss = loss(lin_reg(X), y)
        trainer.zero_grad() # Reset the gradient to zero
        training_loss.backward() # Compute gradient on training_loss
        trainer.step() # Update the weights using the gradient

    training_loss = loss(lin_reg(features), labels) # Compute the loss with the updated weights
    
    print(f'epoch {epoch + 1}, loss {training_loss:f}')
``` 

```{python}
w = lin_reg[0].weight.data
print('Estimated weights w:', w)
b = lin_reg[0].bias.data
print('Estimated intercept/bias b:', b)
```

## Asseing Model Performance

Why it can fail to build up the machine learning model just by minimizing the empircal risk. Its important keep in mind that the target functions will most likely wont be a linear function. 

```{python}
n = 10 # number of oberservations
torch.manual_seed(42) # Set a seed for replicability

features = 2*torch.rand(n,1) - 1
labels = 0.5-1.4*features + 4.4*features**2 - 2.1*features**3 + torch.normal(0,1,(1,n)).reshape(-1,1)
```

```{python}
fig = plt.figure(figsize=(5,4), dpi= 200)
plt.scatter(features, labels, c='r')
x = torch.arange(-1,1,0.01)
fx = 0.5-1.4*x + 4.4*x**2 - 2.1*x**3
plt.plot(x,fx, c='g')
plt.grid(True)
plt.ylim((-2,10))
plt.show()
```

A linear regression is too simple capture the data generating process. 

```{python}
batch_size = 10
data_iter = load_array((features, labels), batch_size)
lin_reg = nn.Sequential(nn.Linear(1,1))
lin_reg[0].weight.data.normal_(0, 0.1)
lin_reg[0].bias.data.fill_(0)
loss = nn.MSELoss()
trainer = torch.optim.SGD(lin_reg.parameters(), lr = 0.03)
num_epochs = 50
for epoch in range (num_epochs):
    for X, y in data_iter:
        training_loss = loss(lin_reg(X), y)
        trainer.zero_grad() # reset the gradient to zero
        training_loss.backward()
        trainer.step()
training_loss = loss(lin_reg(features), labels) #calculate the loss with the updated weights on the whole dataset
print(f'epoch {epoch + 1}, loss {training_loss:f}')
```

```{python}
fig = plt.figure(figsize=(5,4), dpi= 200)
plt.scatter(features, labels, c='r')
fx_hat = lin_reg[0].bias.data + lin_reg[0].weight.data.detach()*x
plt.plot(x,fx, c='g')
plt.plot(x,fx_hat.reshape(-1,1), c='b')
plt.grid(True)
plt.ylim((-2,10))
plt.show()
```

This called underfitting since the machine learning model is too imple and therefore not able to approximate f_0. 

It can be increased the capability of linear regression by using polynomial regression, which increases the flexibility of our machine learning model. BUT if the flexibility is too large, the training process might not converge to a helpful solution, but instead start to "learn" the noise in the data. 

```{python}
max_degr = 10
polynomial_features = features
for degr in range (1,max_degr):
    polynomial_features = torch.cat((polynomial_features, features**(degr+1)), dim= 1)
```

```{python}
batch_size = 10
data_iter = load_array((polynomial_features, labels), batch_size)
lin_reg = nn.Sequential(nn.Linear(max_degr,1))
lin_reg[0].weight.data.normal_(0, 0.01)
lin_reg[0].bias.data.fill_(0)
loss = nn.MSELoss()
trainer = torch.optim.SGD(lin_reg.parameters(), lr = .4)
num_epochs = 50000
for epoch in range (num_epochs):
    for X, y in data_iter:
        training_loss = loss(lin_reg(X), y)
        trainer.zero_grad() # reset the gradient to zero
        training_loss.backward()
        trainer.step()
training_loss = loss(lin_reg(polynomial_features), labels) # calculate the loss with the updated weights on the whole dataset

print(f'epoch {epoch + 1}, loss {training_loss:f}')
```

```{python}
fig = plt.figure(figsize=(5,4), dpi= 200)
plt.scatter(features, labels, c='r')
fx_hat_2 = lin_reg[0].bias.data.detach()+lin_reg[0].weight.data[0,0].detach()*x
for degr in range (1,max_degr):
    fx_hat_2 += lin_reg[0].weight.data[0,degr].detach()*x**(degr+1)
plt.plot(x,fx,c='g')
plt.plot(x,fx_hat_2.reshape(-1,1), c='b')
plt.grid(True)
plt.ylim((-2,10))
plt.show()
``` 

This "learning" of the noise is called overfitting. For example in the context of image recognition this might correspond to learning irrelevant artifacts like backgrounds or shadows.

For the mean-sqaured error under- and overfitting can be motivated with the bias-variance-tradeoff:

To avoid under- and overfitting it is important to monitor model performance during the training procedure.
In general, thi is done by sample splitting.

Sample splitting refers to creating several subsets of your sample, which are used for different purposes.
    - Training set: used to train weights of the machine learning algorithm
    - Testing Set: Used to evaluate the risk of the final model
    - Validation Set: Sometimes the training set is split further to monitor the training process and schoose some tuning parameters.

```{python}
n_test = 20 # number of observations
test_features = 2*torch.rand(n,1) - 1
test_polynomial_features = test_features
for degr in range (1,max_degr):
    test_polynomial_features = torch.cat((test_polynomial_features, test_features**(degr+1)), dim=1)

test_labels = 0.5-1.4*test_features + 4.4*test_features**2 - 2.1*test_features**3 + torch.normal(0,1,(1,n)).reshape(-1,1)

print(f'epoch {epoch + 1}, loss {training_loss:f}') #recap the training loss
test_loss = loss(lin_reg(test_polynomial_features), test_labels) #calculate the loss on the whole training sample
print(f'epoch {epoch + 1}, loss {test_loss:f}')
```