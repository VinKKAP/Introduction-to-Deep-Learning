{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5ReL6BCkhCp"
      },
      "source": [
        "# Tutorial 6\n",
        "\n",
        "At first, we will take a more detailed look at embeddings using Appendix B - 'A Closer Look at Word Embeddings' from [here](https://github.com/bentrevett/pytorch-sentiment-analysis/blob/main/legacy/B%20-%20A%20Closer%20Look%20at%20Word%20Embeddings.ipynb).\n",
        "\n",
        "All of the code is taken from the following [Github page](https://github.com/bentrevett/pytorch-sentiment-analysis), which has a lot additional tutorials to offer.\n",
        "\n",
        "## Embeddings\n",
        "\n",
        "Embeddings transform a one-hot encoded vector (a vector that is 0 in elements except one, which is 1) into a much smaller dimension vector of real numbers. The one-hot encoded vector is also known as a *sparse vector*, whilst the real valued vector is known as a *dense vector*.\n",
        "\n",
        "The key concept in these word embeddings is that words that appear in similar _contexts_ appear nearby in the vector space, i.e. the Euclidean distance between these two word vectors is small. By context here, we mean the surrounding words. For example in the sentences \"I purchased some items at the shop\" and \"I purchased some items at the store\" the words 'shop' and 'store' appear in the same context and thus should be close together in vector space.\n",
        "\n",
        "If you want to know how *word2vec* works, check out a two part series [here](http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/) and [here](http://mccormickml.com/2017/01/11/word2vec-tutorial-part-2-negative-sampling/), and if you want to find out more about *GloVe*, check the website [here](https://nlp.stanford.edu/projects/glove/).\n",
        "\n",
        "In PyTorch, we use word vectors with the `nn.Embedding` layer, which takes a _**[sentence length, batch size]**_ tensor and transforms it into a _**[sentence length, batch size, embedding dimensions]**_ tensor.\n",
        "\n",
        "\n",
        "### Loading the GloVe vectors\n",
        "\n",
        "First, we'll load the GloVe vectors. The `name` field specifies what the vectors have been trained on, here the `6B` means a corpus of 6 billion words. The `dim` argument specifies the dimensionality of the word vectors. GloVe vectors are available in 50, 100, 200 and 300 dimensions. There is also a `42B` and `840B` glove vectors, however they are only available at 300 dimensions.\n",
        "\n",
        "**Note**: these vectors are about 862MB, so watch out if you have a limited internet connection."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install torchtext torch==2.2.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1g9lsVuGZnq",
        "outputId": "f9916306-569d-455c-c769-2b1585c89406"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchtext\n",
            "  Downloading torchtext-0.18.0-cp311-cp311-manylinux1_x86_64.whl.metadata (7.9 kB)\n",
            "Collecting torch==2.2.0\n",
            "  Downloading torch-2.2.0-cp311-cp311-manylinux1_x86_64.whl.metadata (25 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (12.1.105)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.2.0)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (12.1.0.106)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch==2.2.0)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (12.1.105)\n",
            "Collecting triton==2.2.0 (from torch==2.2.0)\n",
            "  Downloading triton-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.0) (12.6.85)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torchtext) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchtext) (2.32.3)\n",
            "INFO: pip is looking at multiple versions of torchtext to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchtext\n",
            "  Downloading torchtext-0.17.2-cp311-cp311-manylinux1_x86_64.whl.metadata (7.9 kB)\n",
            "  Downloading torchtext-0.17.1-cp311-cp311-manylinux1_x86_64.whl.metadata (7.6 kB)\n",
            "  Downloading torchtext-0.17.0-cp311-cp311-manylinux1_x86_64.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchtext) (1.26.4)\n",
            "Collecting torchdata==0.7.1 (from torchtext)\n",
            "  Downloading torchdata-0.7.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.11/dist-packages (from torchdata==0.7.1->torchtext) (2.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.2.0) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext) (2024.12.14)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.2.0) (1.3.0)\n",
            "Downloading torch-2.2.0-cp311-cp311-manylinux1_x86_64.whl (755.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m819.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchtext-0.17.0-cp311-cp311-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchdata-0.7.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m74.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, nvidia-nccl-cu12, nvidia-cudnn-cu12, torch, torchdata, torchtext\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.1.0\n",
            "    Uninstalling triton-3.1.0:\n",
            "      Successfully uninstalled triton-3.1.0\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.1.0.70\n",
            "    Uninstalling nvidia-cudnn-cu12-9.1.0.70:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.1.0.70\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.1+cu121\n",
            "    Uninstalling torch-2.5.1+cu121:\n",
            "      Successfully uninstalled torch-2.5.1+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.20.1+cu121 requires torch==2.5.1, but you have torch 2.2.0 which is incompatible.\n",
            "torchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 2.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cudnn-cu12-8.9.2.26 nvidia-nccl-cu12-2.19.3 torch-2.2.0 torchdata-0.7.1 torchtext-0.17.0 triton-2.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JENOGCzvkhCu",
        "outputId": "fc1543c7-bfe3-4182-a3fe-f63d00ae33a2"
      },
      "source": [
        "import torchtext.vocab\n",
        "\n",
        "glove = torchtext.vocab.GloVe(name = '6B', dim = 50)\n",
        "\n",
        "print(f'There are {len(glove.itos)} words in the vocabulary')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [02:39, 5.39MB/s]                           \n",
            "100%|█████████▉| 399999/400000 [00:16<00:00, 24040.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 400000 words in the vocabulary\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hurXUaSkhCw"
      },
      "source": [
        "As shown above, there are 400,000 unique words in the GloVe vocabulary. These are the most common words found in the corpus the vectors were trained on. **In these set of GloVe vectors, every single word is lower-case only.**\n",
        "\n",
        "`glove.vectors` is the actual tensor containing the values of the embeddings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8IaU2mmkhCw",
        "outputId": "c49d8e8e-4477-4a11-d96e-d04f7b120a8e"
      },
      "source": [
        "glove.vectors.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([400000, 50])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "glove.vectors[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kiQFes1fpAJq",
        "outputId": "dcb4eab2-b181-43b0-b447-0bb44276c48a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 4.1800e-01,  2.4968e-01, -4.1242e-01,  1.2170e-01,  3.4527e-01,\n",
              "        -4.4457e-02, -4.9688e-01, -1.7862e-01, -6.6023e-04, -6.5660e-01,\n",
              "         2.7843e-01, -1.4767e-01, -5.5677e-01,  1.4658e-01, -9.5095e-03,\n",
              "         1.1658e-02,  1.0204e-01, -1.2792e-01, -8.4430e-01, -1.2181e-01,\n",
              "        -1.6801e-02, -3.3279e-01, -1.5520e-01, -2.3131e-01, -1.9181e-01,\n",
              "        -1.8823e+00, -7.6746e-01,  9.9051e-02, -4.2125e-01, -1.9526e-01,\n",
              "         4.0071e+00, -1.8594e-01, -5.2287e-01, -3.1681e-01,  5.9213e-04,\n",
              "         7.4449e-03,  1.7778e-01, -1.5897e-01,  1.2041e-02, -5.4223e-02,\n",
              "        -2.9871e-01, -1.5749e-01, -3.4758e-01, -4.5637e-02, -4.4251e-01,\n",
              "         1.8785e-01,  2.7849e-03, -1.8411e-01, -1.1514e-01, -7.8581e-01])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Pwn7W-DkhCw"
      },
      "source": [
        "We can see what word is associated with each row by checking the `itos` (int to string) list.\n",
        "\n",
        "Below implies that row 0 is the vector associated with the word 'the', row 1 for ',' (comma), row 2 for '.' (period), etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubhWJa7fkhCx",
        "outputId": "3b95fbb4-9dee-40ce-b031-e7829d1c952d"
      },
      "source": [
        "glove.itos[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the', ',', '.', 'of', 'to', 'and', 'in', 'a', '\"', \"'s\"]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pSULglokhCx"
      },
      "source": [
        "We can also use the `stoi` (string to int) dictionary, in which we input a word and receive the associated integer/index. If you try get the index of a word that is not in the vocabulary, you receive an error."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3W1uBpvkhCx",
        "outputId": "e77bba2d-7435-427a-83db-5f8f620a3d15"
      },
      "source": [
        "glove.stoi[\"the\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRSoFnjmkhCy"
      },
      "source": [
        "We can get the vector of a word by first getting the integer associated with it and then indexing into the word embedding tensor with that index."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwP-eGbhkhCy",
        "outputId": "16960fe9-4805-4013-a1ae-a64aa89914db"
      },
      "source": [
        "glove.vectors[glove.stoi['distribution']]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.7140, -0.6182, -0.0561,  0.8156,  0.2053,  0.5305, -0.3795, -1.3388,\n",
              "         1.7468,  0.4604,  1.1172, -0.0601, -0.0469, -0.4204,  0.2040,  0.2522,\n",
              "         0.0595, -0.0693,  0.2508, -0.6176,  0.7069, -0.6959,  0.0909,  0.5258,\n",
              "        -0.9721,  0.0638, -0.1614,  0.0575,  0.7902,  0.3413,  3.2132, -0.1495,\n",
              "         0.1039, -0.8629, -0.4394,  0.0373, -0.3620, -0.0531, -0.0706,  0.7165,\n",
              "         0.5031,  0.2062, -0.3848,  0.1896, -1.2933, -0.1960, -0.1562,  0.3917,\n",
              "        -0.1183,  0.3970])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2yI3W5VkhCy"
      },
      "source": [
        "We'll be doing this a lot, so we'll create a function that takes in word embeddings and a word then returns the associated vector. It'll also throw an error if the word doesn't exist in the vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYW69DCAkhCz"
      },
      "source": [
        "def get_vector(embeddings, word):\n",
        "    assert word in embeddings.stoi, f'*{word}* is not in the vocab!'\n",
        "    return embeddings.vectors[embeddings.stoi[word]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcWFSx6tkhCz"
      },
      "source": [
        "As before, we use a word to get the associated vector."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lz_130bjkhCz",
        "outputId": "59bf4981-2220-4ac8-bfda-75858c51d82f"
      },
      "source": [
        "get_vector(glove, 'test')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.1318, -0.2552, -0.0679,  0.2619, -0.2616,  0.2357,  0.1308, -0.0118,\n",
              "         1.7659,  0.2078,  0.2620, -0.1643, -0.8464,  0.0201,  0.0702,  0.3978,\n",
              "         0.1528, -0.2021, -1.6184, -0.5433, -0.1786,  0.5389,  0.4987, -0.1017,\n",
              "         0.6626, -1.7051,  0.0572, -0.3241, -0.6683,  0.2665,  2.8420,  0.2684,\n",
              "        -0.5954, -0.5004,  1.5199,  0.0396,  1.6659,  0.9976, -0.5597, -0.7049,\n",
              "        -0.0309, -0.2830, -0.1356,  0.6429,  0.4149,  1.2362,  0.7659,  0.9780,\n",
              "         0.5851, -0.3018])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfqpV0hEkhCz"
      },
      "source": [
        "## Similar Contexts\n",
        "\n",
        "Now to start looking at the context of different words.\n",
        "\n",
        "If we want to find the words similar to a certain input word, we first find the vector of this input word, then we scan through our vocabulary calculating the distance between the vector of each word and our input word vector. We then sort these from closest to furthest away.\n",
        "\n",
        "The function below returns the closest 10 words to an input word vector:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghi5wUVBkhCz"
      },
      "source": [
        "import torch\n",
        "\n",
        "def closest_words(embeddings, vector, n = 10):\n",
        "\n",
        "    distances = [(word, torch.dist(vector, get_vector(embeddings, word)).item())\n",
        "                 for word in embeddings.itos]\n",
        "\n",
        "    return sorted(distances, key = lambda w: w[1])[:n]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "norm()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cGpOyhQdMM6",
        "outputId": "d550274d-f96f-4980-b385-997fd26bca4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<scipy.stats._continuous_distns.norm_gen at 0x7b1b1f215510>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.linalg import norm\n",
        "\n",
        "for vec in glove.vectors:\n",
        "  print(norm(vec))"
      ],
      "metadata": {
        "id": "h65L39omc7kl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_vector = get_vector(glove, 'tower')\n",
        "\n",
        "closest_words(glove, word_vector)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSx9s52aI-_O",
        "outputId": "3a64003d-6ff6-4819-bbd6-2556e0ef6212"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('tower', 0.0),\n",
              " ('towers', 2.4298789501190186),\n",
              " ('gate', 3.0436489582061768),\n",
              " ('building', 3.4286906719207764),\n",
              " ('skyscraper', 3.4428133964538574),\n",
              " ('roof', 3.4700679779052734),\n",
              " ('built', 3.4704749584198),\n",
              " ('dome', 3.524683713912964),\n",
              " ('facade', 3.633889675140381),\n",
              " ('constructed', 3.6388208866119385)]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpiIQjXukhC0"
      },
      "source": [
        "Let's try it out with 'korea'. The closest word is the word 'korea' itself (not very interesting), however all of the words are related in some way. Pyongyang is the capital of North Korea, DPRK is the official name of North Korea, etc.\n",
        "\n",
        "Interestingly, we also get 'Japan' and 'China',  implies that Korea, Japan and China are frequently talked about together in similar contexts. This makes sense as they are geographically situated near each other."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIcjZVOYkhC0",
        "outputId": "18cd902e-485c-47fe-8fb2-e18aba6923f3"
      },
      "source": [
        "word_vector = get_vector(glove, 'korea')\n",
        "closest_words(glove, word_vector)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('korea', 0.0),\n",
              " ('korean', 2.937217950820923),\n",
              " ('pyongyang', 3.229891061782837),\n",
              " ('dprk', 3.329789400100708),\n",
              " ('seoul', 3.4446284770965576),\n",
              " ('japan', 3.669916868209839),\n",
              " ('china', 3.727811098098755),\n",
              " ('iran', 3.766406774520874),\n",
              " ('beijing', 3.93996262550354),\n",
              " ('koreans', 4.017017364501953)]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GCtsuY2khC0"
      },
      "source": [
        "Looking at another country, India, we also get nearby countries: Thailand, Malaysia and Sri Lanka (as two separate words). Australia is relatively close to India (geographically), but Thailand and Malaysia are closer. So why is Australia closer to India in vector space? This is most probably due to India and Australia appearing in the context of [cricket](https://en.wikipedia.org/wiki/Cricket) matches together."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bgs78urpkhC0",
        "outputId": "8e981b92-aa0a-4e44-d280-83aaec84934a"
      },
      "source": [
        "word_vector = get_vector(glove, 'the')\n",
        "\n",
        "closest_words(glove, word_vector)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('the', 0.0),\n",
              " ('which', 1.9375851154327393),\n",
              " ('part', 1.9737050533294678),\n",
              " ('of', 2.189652919769287),\n",
              " ('in', 2.193087339401245),\n",
              " ('on', 2.2333903312683105),\n",
              " ('one', 2.2391767501831055),\n",
              " ('.', 2.248121738433838),\n",
              " ('as', 2.264446258544922),\n",
              " ('same', 2.3636555671691895)]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3sxBndDkhC0"
      },
      "source": [
        "We'll also create another function that will nicely print out the tuples returned by our `closest_words` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKmSP7ZdkhC1"
      },
      "source": [
        "def print_tuples(tuples):\n",
        "    for w, d in tuples:\n",
        "        print(f'({d:02.04f}) {w}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwiOUmbHkhC1"
      },
      "source": [
        "A final word to look at, 'sports'. As we can see, the closest words are most of the sports themselves."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOIc6MMvkhC1",
        "outputId": "1f121a65-3513-46c6-8421-4cb731be7eb3"
      },
      "source": [
        "word_vector = get_vector(glove, 'the')\n",
        "\n",
        "print_tuples(closest_words(glove, word_vector))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0.0000) the\n",
            "(1.9376) which\n",
            "(1.9737) part\n",
            "(2.1897) of\n",
            "(2.1931) in\n",
            "(2.2334) on\n",
            "(2.2392) one\n",
            "(2.2481) .\n",
            "(2.2644) as\n",
            "(2.3637) same\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRmUS-btkhC1"
      },
      "source": [
        "## Analogies\n",
        "\n",
        "Another property of word embeddings is that they can be operated on just as any standard vector and give interesting results.\n",
        "\n",
        "We'll show an example of this first, and then explain it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4f-2aWYkhC1"
      },
      "source": [
        "def analogy(embeddings, word1, word2, word3, n=5):\n",
        "\n",
        "    #get vectors for each word\n",
        "    word1_vector = get_vector(embeddings, word1)\n",
        "    word2_vector = get_vector(embeddings, word2)\n",
        "    word3_vector = get_vector(embeddings, word3)\n",
        "\n",
        "    #calculate analogy vector\n",
        "    analogy_vector = word2_vector - word1_vector + word3_vector\n",
        "\n",
        "    #find closest words to analogy vector\n",
        "    candidate_words = closest_words(embeddings, analogy_vector, n+3)\n",
        "\n",
        "    #filter out words already in analogy\n",
        "    candidate_words = [(word, dist) for (word, dist) in candidate_words\n",
        "                       if word not in [word1, word2, word3]][:n]\n",
        "\n",
        "    print(f'{word1} is to {word2} as {word3} is to...')\n",
        "\n",
        "    return candidate_words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cs9x4JidkhC2",
        "outputId": "b49fc52b-5637-4fc7-e0ac-c8bd5011a599"
      },
      "source": [
        "print_tuples(analogy(glove, 'male', 'king', 'female'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "male is to king as female is to...\n",
            "(3.1078) prince\n",
            "(3.5638) uncle\n",
            "(3.6519) brother\n",
            "(3.6756) queen\n",
            "(3.7817) grandson\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0t3dCJi1khC2"
      },
      "source": [
        "This is the canonical example which shows off this property of word embeddings. So why does it work? Why does the vector of 'woman' added to the vector of 'king' minus the vector of 'man' give us 'queen'?\n",
        "\n",
        "If we think about it, the vector calculated from 'king' minus 'man' gives us a \"royalty vector\". This is the vector associated with traveling from a man to his royal counterpart, a king. If we add this \"royality vector\" to 'woman', this should travel to her royal equivalent, which is a queen!\n",
        "\n",
        "We can do this with other analogies too. For example, this gets an \"acting career vector\":"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnIt9t2ukhC2",
        "outputId": "e27bad88-a9b2-471b-efb9-4f3e11a83c9f"
      },
      "source": [
        "print_tuples(analogy(glove, 'distribution', 'probability', 'expectation'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "distribution is to probability as expectation is to...\n",
            "(5.0663) certainty\n",
            "(5.5545) likelihood\n",
            "(5.6148) calculated\n",
            "(5.6347) inclination\n",
            "(5.6383) downside\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6vAxGlOkhC3"
      },
      "source": [
        "For a \"baby animal vector\":"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmD5gKilkhC3",
        "outputId": "a82703a6-f16b-469a-c332-869b4839e0ed"
      },
      "source": [
        "print_tuples(analogy(glove, 'cat', 'kitten', 'dog'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cat is to kitten as dog is to...\n",
            "(3.0314) puppy\n",
            "(3.2785) rottweiler\n",
            "(3.5163) spunky\n",
            "(3.5478) toddler\n",
            "(3.5482) mannequin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4uwFtyKtkhC3"
      },
      "source": [
        "A \"capital city vector\":"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txSyzCCBkhC3",
        "outputId": "f691ea19-879a-42bb-8eb6-56bb486b822c"
      },
      "source": [
        "print_tuples(analogy(glove, 'france', 'paris', 'germany'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "france is to paris as germany is to...\n",
            "(2.3015) berlin\n",
            "(3.4018) vienna\n",
            "(3.4697) munich\n",
            "(3.4750) frankfurt\n",
            "(3.5025) hamburg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZhbdtFzkhC3"
      },
      "source": [
        "A \"musician's genre vector\":"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kseyP37ikhC3",
        "outputId": "e8c07e14-5615-455f-d7f9-5b3d09ad47cd"
      },
      "source": [
        "print_tuples(analogy(glove, 'elvis', 'rock', 'eminem'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elvis is to rock as eminem is to...\n",
            "(4.5673) rap\n",
            "(5.1407) hip-hop\n",
            "(5.1510) rappers\n",
            "(5.2317) hop\n",
            "(5.2441) rapper\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peD5V7cqkhC4"
      },
      "source": [
        "And an \"ingredient vector\":"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5kZJATWkhC4",
        "outputId": "747136a1-85c0-4f48-8c15-8de7d35b3c92"
      },
      "source": [
        "print_tuples(analogy(glove, 'beer', 'barley', 'wine'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "beer is to barley as wine is to...\n",
            "(4.1063) grape\n",
            "(4.4254) legumes\n",
            "(4.4577) grapes\n",
            "(4.4731) varieties\n",
            "(4.5731) beans\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sDhkOoULWWA"
      },
      "source": [
        "## Bonus (A Short Intro to Neural Style Transfer)\n",
        "\n",
        "Take a look at the following [tutorial](https://pytorch.org/tutorials/advanced/neural_style_tutorial.html)."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h8RZ-o-qUtuM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}